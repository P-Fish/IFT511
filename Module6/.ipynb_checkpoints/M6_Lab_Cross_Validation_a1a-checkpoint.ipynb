{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M6 Lab: Model Selection with K-Fold Cross Validation (a1a dataset)\n",
    "\n",
    "This lab demonstrates K-Fold Cross Validation using scikit-learn with Support Vector Machine (SVM) classifiers.\n",
    "\n",
    "**Using a1a dataset - smaller and faster for demonstration purposes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Understanding the Model Parameters\n",
    "\n",
    "### SVM Classifier Parameters Explanation:\n",
    "\n",
    "- **C**: Regularization parameter. Controls the trade-off between achieving a low training error and a low testing error (generalization). Smaller values create a wider margin but may misclassify more points. Default is 1.0.\n",
    "\n",
    "- **kernel**: Specifies the kernel type to be used in the algorithm. Options include 'linear', 'poly', 'rbf', 'sigmoid'. The kernel function transforms the data into a higher dimensional space.\n",
    "\n",
    "- **degree**: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels. Default is 3.\n",
    "\n",
    "- **gamma**: Kernel coefficient for 'rbf', 'poly' and 'sigmoid'. Defines how far the influence of a single training example reaches. Low values mean 'far' and high values mean 'close'. Default is 'scale'.\n",
    "\n",
    "- **coef0**: Independent term in kernel function. It is only significant in 'poly' and 'sigmoid'. Default is 0.0.\n",
    "\n",
    "- **tol**: Tolerance for stopping criterion. The algorithm stops when the optimization improvement is below this threshold. Default is 1e-3.\n",
    "\n",
    "- **verbose**: Enable verbose output during training. Controls the amount of detail printed during fitting. Default is False.\n",
    "\n",
    "- **max_iter**: Hard limit on iterations within solver. -1 means no limit. Default is -1.\n",
    "\n",
    "- **decision_function_shape**: Determines the shape of the decision function. 'ovo' (one-vs-one) or 'ovr' (one-vs-rest). Default is 'ovr'.\n",
    "\n",
    "- **random_state**: Controls the random number generation for shuffling the data. Pass an int for reproducible output across multiple function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Simple Cross Validation\n",
    "\n",
    "In this section, we'll perform basic cross-validation with different kernel configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Dataset...\")\n",
    "X, y = load_svmlight_file(\"a1a.txt\")\n",
    "print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Linear Kernel with C=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating classifier object...\")\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "\n",
    "print(\"Training classifier with cross validation, k=5\")\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "acc = scores.mean()\n",
    "stdiv = scores.std()\n",
    "\n",
    "print(f\"Cross Validation Mean Accuracy = {acc:.2f}\")\n",
    "print(f\"Standard Deviation of the Mean Accuracy across all runs = {stdiv:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: RBF Kernel with gamma=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating classifier with RBF kernel, gamma=0.1...\")\n",
    "clf = svm.SVC(kernel='rbf', gamma=0.1, random_state=42)\n",
    "\n",
    "print(\"Training classifier with cross validation, k=5\")\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "acc = scores.mean()\n",
    "stdiv = scores.std()\n",
    "\n",
    "print(f\"Cross Validation Mean Accuracy = {acc:.2f}\")\n",
    "print(f\"Standard Deviation of the Mean Accuracy across all runs = {stdiv:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: RBF Kernel with gamma=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating classifier with RBF kernel, gamma=0.01...\")\n",
    "clf = svm.SVC(kernel='rbf', gamma=0.01, random_state=42)\n",
    "\n",
    "print(\"Training classifier with cross validation, k=5\")\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "acc = scores.mean()\n",
    "stdiv = scores.std()\n",
    "\n",
    "print(f\"Cross Validation Mean Accuracy = {acc:.2f}\")\n",
    "print(f\"Standard Deviation of the Mean Accuracy across all runs = {stdiv:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Polynomial Kernel with degree=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating classifier with polynomial kernel, degree=2...\")\n",
    "clf = svm.SVC(kernel='poly', degree=2, random_state=42)\n",
    "\n",
    "print(\"Training classifier with cross validation, k=5\")\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "acc = scores.mean()\n",
    "stdiv = scores.std()\n",
    "\n",
    "print(f\"Cross Validation Mean Accuracy = {acc:.2f}\")\n",
    "print(f\"Standard Deviation of the Mean Accuracy across all runs = {stdiv:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Parameter Fine Tuning\n",
    "\n",
    "Now we'll use GridSearchCV to systematically test multiple parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Grid Search (Original Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Dataset...\")\n",
    "X, y = load_svmlight_file(\"a1a.txt\")\n",
    "\n",
    "print(\"Creating Parameter Grid...\")\n",
    "param_grid = [\n",
    "    {'C': [1, 10], 'kernel': ['linear']},\n",
    "    {'C': [1, 10], 'gamma': [0.001, 0.01], 'kernel': ['rbf']},\n",
    "]\n",
    "\n",
    "print(\"Creating classifier object...\")\n",
    "svc = svm.SVC()\n",
    "\n",
    "print(\"Creating a grid search cross validator object...\")\n",
    "clf = GridSearchCV(svc, param_grid)\n",
    "\n",
    "print(\"Fitting the models with different parameters...\")\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(\"Writing all fitting results...\")\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df.to_csv(\"Parameter_Tuning_Results_a1a.csv\")\n",
    "\n",
    "print(\"Results saved to Parameter_Tuning_Results_a1a.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info about the results\n",
    "print(\"\\nColumns in the results dataframe:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\nNumber of parameter combinations tested:\", len(df))\n",
    "\n",
    "print(\"\\nBest parameters found:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "print(\"\\nBest cross-validation score:\")\n",
    "print(f\"{clf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Grid Search with Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating Extended Parameter Grid with Polynomial Kernel...\")\n",
    "param_grid_extended = [\n",
    "    {'C': [0.01, 0.1, 1, 10], 'kernel': ['linear']},\n",
    "    {'C': [0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01], 'kernel': ['rbf']},\n",
    "    {'C': [0.01, 0.1, 1, 10], 'degree': [2, 3], 'kernel': ['poly']},\n",
    "]\n",
    "\n",
    "print(\"Creating classifier object...\")\n",
    "svc = svm.SVC()\n",
    "\n",
    "print(\"Creating a grid search cross validator object...\")\n",
    "clf_extended = GridSearchCV(svc, param_grid_extended)\n",
    "\n",
    "print(\"Fitting the models with different parameters...\")\n",
    "clf_extended.fit(X, y)\n",
    "\n",
    "print(\"Writing all fitting results...\")\n",
    "df_extended = pd.DataFrame(clf_extended.cv_results_)\n",
    "df_extended.to_csv(\"Parameter_Tuning_Results_Extended_a1a.csv\")\n",
    "\n",
    "print(\"Results saved to Parameter_Tuning_Results_Extended_a1a.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Ranked Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by rank and display results\n",
    "results_sorted = df_extended.sort_values('rank_test_score')\n",
    "\n",
    "print(\"\\nRanked Parameter Sets:\\n\")\n",
    "for idx, row in results_sorted.iterrows():\n",
    "    rank = row['rank_test_score']\n",
    "    params = row['params']\n",
    "    mean_acc = row['mean_test_score']\n",
    "    std_dev = row['std_test_score']\n",
    "    \n",
    "    print(f\"Rank {rank}: {params}, Mean Test Accuracy={mean_acc}, Mean StdDev={std_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Top 5 Results in a Clean Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 5 results in a more readable format\n",
    "print(\"\\nTop 5 Parameter Combinations:\\n\")\n",
    "top_5 = results_sorted.head(5)\n",
    "display_cols = ['rank_test_score', 'params', 'mean_test_score', 'std_test_score']\n",
    "print(top_5[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit: K-Fold Cross Validation with Different Testing Folds\n",
    "\n",
    "Implementing standard K-Fold CV where each fold serves as the test set once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Dataset...\")\n",
    "X, y = load_svmlight_file(\"a1a.txt\")\n",
    "\n",
    "# Setup K-Fold with K=5\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Model configurations to test\n",
    "models = [\n",
    "    ('Linear', svm.SVC(kernel='linear', random_state=42)),\n",
    "    ('RBF gamma=0.01', svm.SVC(kernel='rbf', gamma=0.01, random_state=42)),\n",
    "    ('RBF gamma=0.001', svm.SVC(kernel='rbf', gamma=0.001, random_state=42))\n",
    "]\n",
    "\n",
    "print(\"\\nRunning K-Fold Cross Validation with K=5\\n\")\n",
    "\n",
    "# Test each model\n",
    "for model_name, model in models:\n",
    "    print(f\"Testing {model_name}...\")\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    fold_num = 1\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        # Split data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and calculate accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"  Fold {fold_num}: Accuracy = {accuracy:.4f}\")\n",
    "        fold_num += 1\n",
    "    \n",
    "    # Calculate average\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    \n",
    "    print(f\"  Average Accuracy: {avg_accuracy:.4f}\")\n",
    "    print(f\"  Standard Deviation: {std_accuracy:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY: Which model gives the highest accuracy?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_summary = []\n",
    "for model_name, model in models:\n",
    "    fold_accuracies = []\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        fold_accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    avg_acc = np.mean(fold_accuracies)\n",
    "    results_summary.append((model_name, avg_acc))\n",
    "\n",
    "# Sort by accuracy\n",
    "results_summary.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (name, acc) in enumerate(results_summary, 1):\n",
    "    print(f\"{i}. {name}: {acc:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Model: {results_summary[0][0]} with accuracy {results_summary[0][1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
