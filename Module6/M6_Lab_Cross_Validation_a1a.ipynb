{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M6 Lab: Model Selection with K-Fold Cross Validation (a1a dataset)\n",
    "\n",
    "This lab demonstrates K-Fold Cross Validation using scikit-learn with Support Vector Machine (SVM) classifiers.\n",
    "\n",
    "**Using a1a dataset - smaller and faster for demonstration purposes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Understanding the Model Parameters\n",
    "\n",
    "### SVM Classifier Parameters Explanation:\n",
    "\n",
    "- **C**: Regularization parameter. Controls the trade-off between achieving a low training error and a low testing error (generalization). Smaller values create a wider margin but may misclassify more points. Default is 1.0.\n",
    "\n",
    "- **kernel**: Specifies the kernel type to be used in the algorithm. Options include 'linear', 'poly', 'rbf', 'sigmoid'. The kernel function transforms the data into a higher dimensional space.\n",
    "\n",
    "- **degree**: Degree of the polynomial kernel function ('poly'). Ignored by all other kernels. Default is 3.\n",
    "\n",
    "- **gamma**: Kernel coefficient for 'rbf', 'poly' and 'sigmoid'. Defines how far the influence of a single training example reaches. Low values mean 'far' and high values mean 'close'. Default is 'scale'.\n",
    "\n",
    "- **coef0**: Independent term in kernel function. It is only significant in 'poly' and 'sigmoid'. Default is 0.0.\n",
    "\n",
    "- **tol**: Tolerance for stopping criterion. The algorithm stops when the optimization improvement is below this threshold. Default is 1e-3.\n",
    "\n",
    "- **verbose**: Enable verbose output during training. Controls the amount of detail printed during fitting. Default is False.\n",
    "\n",
    "- **max_iter**: Hard limit on iterations within solver. -1 means no limit. Default is -1.\n",
    "\n",
    "- **decision_function_shape**: Determines the shape of the decision function. 'ovo' (one-vs-one) or 'ovr' (one-vs-rest). Default is 'ovr'.\n",
    "\n",
    "- **random_state**: Controls the random number generation for shuffling the data. Pass an int for reproducible output across multiple function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Simple Cross Validation\n",
    "\n",
    "In this section, we'll perform basic cross-validation with different kernel configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset...\n",
      "Dataset loaded: 1605 samples, 119 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Dataset...\")\n",
    "X, y = load_svmlight_file(\"a1a.txt\")\n",
    "print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Linear Kernel with C=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating classifier object...\n",
      "Training classifier with cross validation, k=5\n",
      "Training Complete!\n",
      "Cross Validation Mean Accuracy = 0.83\n",
      "Standard Deviation of the Mean Accuracy across all runs = 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating classifier object...\")\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "\n",
    "print(\"Training classifier with cross validation, k=5\")\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "acc = scores.mean()\n",
    "stdiv = scores.std()\n",
    "\n",
    "print(f\"Cross Validation Mean Accuracy = {acc:.2f}\")\n",
    "print(f\"Standard Deviation of the Mean Accuracy across all runs = {stdiv:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: RBF Kernel with gamma=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating classifier with RBF kernel, gamma=0.1...\n",
      "Training classifier with cross validation, k=5\n",
      "Training Complete!\n",
      "Cross Validation Mean Accuracy = 0.83\n",
      "Standard Deviation of the Mean Accuracy across all runs = 0.03\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating classifier with RBF kernel, gamma=0.1...\")\n",
    "clf = svm.SVC(kernel='rbf', gamma=0.1, random_state=42)\n",
    "\n",
    "print(\"Training classifier with cross validation, k=5\")\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "acc = scores.mean()\n",
    "stdiv = scores.std()\n",
    "\n",
    "print(f\"Cross Validation Mean Accuracy = {acc:.2f}\")\n",
    "print(f\"Standard Deviation of the Mean Accuracy across all runs = {stdiv:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: RBF Kernel with gamma=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating classifier with RBF kernel, gamma=0.01...\n",
      "Training classifier with cross validation, k=5\n",
      "Training Complete!\n",
      "Cross Validation Mean Accuracy = 0.82\n",
      "Standard Deviation of the Mean Accuracy across all runs = 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating classifier with RBF kernel, gamma=0.01...\")\n",
    "clf = svm.SVC(kernel='rbf', gamma=0.01, random_state=42)\n",
    "\n",
    "print(\"Training classifier with cross validation, k=5\")\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "acc = scores.mean()\n",
    "stdiv = scores.std()\n",
    "\n",
    "print(f\"Cross Validation Mean Accuracy = {acc:.2f}\")\n",
    "print(f\"Standard Deviation of the Mean Accuracy across all runs = {stdiv:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Polynomial Kernel with degree=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating classifier with polynomial kernel, degree=2...\n",
      "Training classifier with cross validation, k=5\n",
      "Training Complete!\n",
      "Cross Validation Mean Accuracy = 0.83\n",
      "Standard Deviation of the Mean Accuracy across all runs = 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating classifier with polynomial kernel, degree=2...\")\n",
    "clf = svm.SVC(kernel='poly', degree=2, random_state=42)\n",
    "\n",
    "print(\"Training classifier with cross validation, k=5\")\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "acc = scores.mean()\n",
    "stdiv = scores.std()\n",
    "\n",
    "print(f\"Cross Validation Mean Accuracy = {acc:.2f}\")\n",
    "print(f\"Standard Deviation of the Mean Accuracy across all runs = {stdiv:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Parameter Fine Tuning\n",
    "\n",
    "Now we'll use GridSearchCV to systematically test multiple parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Grid Search (Original Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset...\n",
      "Creating Parameter Grid...\n",
      "Creating classifier object...\n",
      "Creating a grid search cross validator object...\n",
      "Fitting the models with different parameters...\n",
      "Writing all fitting results...\n",
      "Results saved to Parameter_Tuning_Results_a1a.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Dataset...\")\n",
    "X, y = load_svmlight_file(\"a1a.txt\")\n",
    "\n",
    "print(\"Creating Parameter Grid...\")\n",
    "param_grid = [\n",
    "    {'C': [1, 10], 'kernel': ['linear']},\n",
    "    {'C': [1, 10], 'gamma': [0.001, 0.01], 'kernel': ['rbf']},\n",
    "]\n",
    "\n",
    "print(\"Creating classifier object...\")\n",
    "svc = svm.SVC()\n",
    "\n",
    "print(\"Creating a grid search cross validator object...\")\n",
    "clf = GridSearchCV(svc, param_grid)\n",
    "\n",
    "print(\"Fitting the models with different parameters...\")\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(\"Writing all fitting results...\")\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df.to_csv(\"Parameter_Tuning_Results_a1a.csv\")\n",
    "\n",
    "print(\"Results saved to Parameter_Tuning_Results_a1a.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in the results dataframe:\n",
      "['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_kernel', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
      "\n",
      "Number of parameter combinations tested: 6\n",
      "\n",
      "Best parameters found:\n",
      "{'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "Best cross-validation score:\n",
      "0.8287\n"
     ]
    }
   ],
   "source": [
    "# Display basic info about the results\n",
    "print(\"\\nColumns in the results dataframe:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\nNumber of parameter combinations tested:\", len(df))\n",
    "\n",
    "print(\"\\nBest parameters found:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "print(\"\\nBest cross-validation score:\")\n",
    "print(f\"{clf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Grid Search with Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Extended Parameter Grid with Polynomial Kernel...\n",
      "Creating classifier object...\n",
      "Creating a grid search cross validator object...\n",
      "Fitting the models with different parameters...\n",
      "Writing all fitting results...\n",
      "Results saved to Parameter_Tuning_Results_Extended_a1a.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Extended Parameter Grid with Polynomial Kernel...\")\n",
    "param_grid_extended = [\n",
    "    {'C': [0.01, 0.1, 1, 10], 'kernel': ['linear']},\n",
    "    {'C': [0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01], 'kernel': ['rbf']},\n",
    "    {'C': [0.01, 0.1, 1, 10], 'degree': [2, 3], 'kernel': ['poly']},\n",
    "]\n",
    "\n",
    "print(\"Creating classifier object...\")\n",
    "svc = svm.SVC()\n",
    "\n",
    "print(\"Creating a grid search cross validator object...\")\n",
    "clf_extended = GridSearchCV(svc, param_grid_extended)\n",
    "\n",
    "print(\"Fitting the models with different parameters...\")\n",
    "clf_extended.fit(X, y)\n",
    "\n",
    "print(\"Writing all fitting results...\")\n",
    "df_extended = pd.DataFrame(clf_extended.cv_results_)\n",
    "df_extended.to_csv(\"Parameter_Tuning_Results_Extended_a1a.csv\")\n",
    "\n",
    "print(\"Results saved to Parameter_Tuning_Results_Extended_a1a.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Ranked Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranked Parameter Sets:\n",
      "\n",
      "Rank 1: {'C': 0.1, 'kernel': 'linear'}, Mean Test Accuracy=0.8317757009345794, Mean StdDev=0.02094421970588363\n",
      "Rank 1: {'C': 1, 'degree': 2, 'kernel': 'poly'}, Mean Test Accuracy=0.8317757009345794, Mean StdDev=0.024922118380062308\n",
      "Rank 3: {'C': 1, 'degree': 3, 'kernel': 'poly'}, Mean Test Accuracy=0.8305295950155763, Mean StdDev=0.025809738538576925\n",
      "Rank 4: {'C': 10, 'kernel': 'linear'}, Mean Test Accuracy=0.8286604361370715, Mean StdDev=0.020092854201367107\n",
      "Rank 5: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}, Mean Test Accuracy=0.8274143302180686, Mean StdDev=0.023445342956045834\n",
      "Rank 6: {'C': 1, 'kernel': 'linear'}, Mean Test Accuracy=0.8274143302180684, Mean StdDev=0.020054176871565212\n",
      "Rank 7: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}, Mean Test Accuracy=0.8249221183800624, Mean StdDev=0.023593889381634255\n",
      "Rank 8: {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}, Mean Test Accuracy=0.8230529595015575, Mean StdDev=0.02464014944957656\n",
      "Rank 9: {'C': 0.1, 'degree': 2, 'kernel': 'poly'}, Mean Test Accuracy=0.8137071651090343, Mean StdDev=0.01799318265195471\n",
      "Rank 9: {'C': 0.01, 'kernel': 'linear'}, Mean Test Accuracy=0.8137071651090343, Mean StdDev=0.01412558759969425\n",
      "Rank 11: {'C': 10, 'degree': 2, 'kernel': 'poly'}, Mean Test Accuracy=0.811214953271028, Mean StdDev=0.017017445836445686\n",
      "Rank 12: {'C': 0.1, 'degree': 3, 'kernel': 'poly'}, Mean Test Accuracy=0.8080996884735201, Mean StdDev=0.02172659909552984\n",
      "Rank 13: {'C': 10, 'degree': 3, 'kernel': 'poly'}, Mean Test Accuracy=0.7968847352024921, Mean StdDev=0.01426233413365682\n",
      "Rank 14: {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}, Mean Test Accuracy=0.7538940809968847, Mean StdDev=0.0\n",
      "Rank 14: {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}, Mean Test Accuracy=0.7538940809968847, Mean StdDev=0.0\n",
      "Rank 14: {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}, Mean Test Accuracy=0.7538940809968847, Mean StdDev=0.0\n",
      "Rank 14: {'C': 0.01, 'degree': 2, 'kernel': 'poly'}, Mean Test Accuracy=0.7538940809968847, Mean StdDev=0.0\n",
      "Rank 14: {'C': 0.01, 'degree': 3, 'kernel': 'poly'}, Mean Test Accuracy=0.7538940809968847, Mean StdDev=0.0\n",
      "Rank 14: {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}, Mean Test Accuracy=0.7538940809968847, Mean StdDev=0.0\n",
      "Rank 14: {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}, Mean Test Accuracy=0.7538940809968847, Mean StdDev=0.0\n"
     ]
    }
   ],
   "source": [
    "# Sort by rank and display results\n",
    "results_sorted = df_extended.sort_values('rank_test_score')\n",
    "\n",
    "print(\"\\nRanked Parameter Sets:\\n\")\n",
    "for idx, row in results_sorted.iterrows():\n",
    "    rank = row['rank_test_score']\n",
    "    params = row['params']\n",
    "    mean_acc = row['mean_test_score']\n",
    "    std_dev = row['std_test_score']\n",
    "    \n",
    "    print(f\"Rank {rank}: {params}, Mean Test Accuracy={mean_acc}, Mean StdDev={std_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Top 5 Results in a Clean Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Parameter Combinations:\n",
      "\n",
      " rank_test_score                                    params  mean_test_score  std_test_score\n",
      "               1            {'C': 0.1, 'kernel': 'linear'}         0.831776        0.020944\n",
      "               1   {'C': 1, 'degree': 2, 'kernel': 'poly'}         0.831776        0.024922\n",
      "               3   {'C': 1, 'degree': 3, 'kernel': 'poly'}         0.830530        0.025810\n",
      "               4             {'C': 10, 'kernel': 'linear'}         0.828660        0.020093\n",
      "               5 {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}         0.827414        0.023445\n"
     ]
    }
   ],
   "source": [
    "# Show top 5 results in a more readable format\n",
    "print(\"\\nTop 5 Parameter Combinations:\\n\")\n",
    "top_5 = results_sorted.head(5)\n",
    "display_cols = ['rank_test_score', 'params', 'mean_test_score', 'std_test_score']\n",
    "print(top_5[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit: K-Fold Cross Validation with Different Testing Folds\n",
    "\n",
    "Implementing standard K-Fold CV where each fold serves as the test set once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset...\n",
      "\n",
      "Running K-Fold Cross Validation with K=5\n",
      "\n",
      "Testing Linear...\n",
      "  Fold 1: Accuracy = 0.8380\n",
      "  Fold 2: Accuracy = 0.8193\n",
      "  Fold 3: Accuracy = 0.8411\n",
      "  Fold 4: Accuracy = 0.8318\n",
      "  Fold 5: Accuracy = 0.8505\n",
      "  Average Accuracy: 0.8361\n",
      "  Standard Deviation: 0.0104\n",
      "\n",
      "Testing RBF gamma=0.01...\n",
      "  Fold 1: Accuracy = 0.8193\n",
      "  Fold 2: Accuracy = 0.8349\n",
      "  Fold 3: Accuracy = 0.8505\n",
      "  Fold 4: Accuracy = 0.8131\n",
      "  Fold 5: Accuracy = 0.8318\n",
      "  Average Accuracy: 0.8299\n",
      "  Standard Deviation: 0.0130\n",
      "\n",
      "Testing RBF gamma=0.001...\n",
      "  Fold 1: Accuracy = 0.7414\n",
      "  Fold 2: Accuracy = 0.7539\n",
      "  Fold 3: Accuracy = 0.7850\n",
      "  Fold 4: Accuracy = 0.7227\n",
      "  Fold 5: Accuracy = 0.7664\n",
      "  Average Accuracy: 0.7539\n",
      "  Standard Deviation: 0.0212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Dataset...\")\n",
    "X, y = load_svmlight_file(\"a1a.txt\")\n",
    "\n",
    "# Setup K-Fold with K=5\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Model configurations to test\n",
    "models = [\n",
    "    ('Linear', svm.SVC(kernel='linear', random_state=42)),\n",
    "    ('RBF gamma=0.01', svm.SVC(kernel='rbf', gamma=0.01, random_state=42)),\n",
    "    ('RBF gamma=0.001', svm.SVC(kernel='rbf', gamma=0.001, random_state=42))\n",
    "]\n",
    "\n",
    "print(\"\\nRunning K-Fold Cross Validation with K=5\\n\")\n",
    "\n",
    "# Test each model\n",
    "for model_name, model in models:\n",
    "    print(f\"Testing {model_name}...\")\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    fold_num = 1\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        # Split data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and calculate accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"  Fold {fold_num}: Accuracy = {accuracy:.4f}\")\n",
    "        fold_num += 1\n",
    "    \n",
    "    # Calculate average\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    \n",
    "    print(f\"  Average Accuracy: {avg_accuracy:.4f}\")\n",
    "    print(f\"  Standard Deviation: {std_accuracy:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY: Which model gives the highest accuracy?\n",
      "============================================================\n",
      "1. Linear: 0.8361\n",
      "2. RBF gamma=0.01: 0.8299\n",
      "3. RBF gamma=0.001: 0.7539\n",
      "\n",
      "Best Model: Linear with accuracy 0.8361\n"
     ]
    }
   ],
   "source": [
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY: Which model gives the highest accuracy?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_summary = []\n",
    "for model_name, model in models:\n",
    "    fold_accuracies = []\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        fold_accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    avg_acc = np.mean(fold_accuracies)\n",
    "    results_summary.append((model_name, avg_acc))\n",
    "\n",
    "# Sort by accuracy\n",
    "results_summary.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (name, acc) in enumerate(results_summary, 1):\n",
    "    print(f\"{i}. {name}: {acc:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Model: {results_summary[0][0]} with accuracy {results_summary[0][1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
